<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BehaveData</title>
    <description>BehaveData é uma comunidade para Data Scientists.</description>
    <link>http://www.behavedata.com/</link>
    <atom:link href="http://www.behavedata.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 25 Jan 2016 22:07:30 -0200</pubDate>
    <lastBuildDate>Mon, 25 Jan 2016 22:07:30 -0200</lastBuildDate>
    <generator>Jekyll v3.1.0</generator>
    
      <item>
        <title>Classificando passos com o Jawbone</title>
        <description>&lt;p&gt;A &lt;a href=&quot;https://jawbone.com&quot; targer=&quot;_blank&quot;&gt;Jawbone&lt;/a&gt; publicou um 
&lt;a href=&quot;https://jawbone.com/blog/classifying-steps-machine-learning/&quot; target=&quot;_blank&quot;&gt;post&lt;/a&gt;  muito
interessante sobre classificação de passos (nossos passos ao caminhar)
utilizando Machine Learning. 
Para quem não conhece, a Jawbone é focada em tecnologia para o
consumidor e principalmente dispositivos wearable. Um dos produtos de
mais destaque da Jawbone é o sistema UP de monitoramento. Eu tenho uma
UP24 e acompanho diariamente os meus passos :).&lt;/p&gt;

&lt;p&gt;O post da Jawbone me chamou a atenção porque, apesar de ser sobre
Machine Learning e classificação, o foco não é o algoritmo mas sim como
modelar o problema e construir o dataset para experimentação. Imaginem o
desafio de construir um dataset representativo
de passos - quais features utilizar? Como representar pessoas altas e
baixas? Apressadas? Utilizando o celular? Puxando uma mala? A escolha
das instâncias do dataset e suas features é fundamental para o sucesso
do modelo preditivo.&lt;/p&gt;

&lt;p&gt;Esse post me fez lembrar que muitas vezes há uma grande ênfase no
algoritmos para classificação. No Kaggle, por exemplo, o objetivo da
maioria das competições é encontrar 
o algoritmo com o melhor resultado. O problema desta abordagem, é
que a parte mais difícil e interessante do processo de modelagem
preditiva já foi resolvida. Na maioria dos projetos de modelagem
preditiva que participei a parte mais difícil sempre foi a
construção do dataset:&lt;/p&gt;

&lt;p&gt;Como escolher instâncias que sejam representativas da população de
interesse?
Como representar essas instâncias? Quais features utilizar?
Como representar a variável resposta?
Como evitar data leakage (quando a variável resposta acaba “vazando”
para uma feature)?
Como incorporar novas instâncias? 
Quando o modelo preditivo precisa ser atualizado?&lt;/p&gt;

&lt;p&gt;Este desafio se torna ainda maior quando o objetivo é modelar
fenômenos sociais. Confira o post da Jawbone que é um bom exemplo do
processo de modelar um problema de predição, 
desde as escolhas instâncias, features e atualização do modelo.&lt;/p&gt;

</description>
        <pubDate>Sun, 18 Oct 2015 01:00:00 -0200</pubDate>
        <link>http://www.behavedata.com/blog/machine-learning/2015/10/18/classificando-passos-jawbone/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/machine-learning/2015/10/18/classificando-passos-jawbone/</guid>
        
        
        <category>machine-learning</category>
        
      </item>
    
      <item>
        <title>Algumas informações úteis sobre Machine Learning</title>
        <description>&lt;p&gt;Nota: Este post é uma adaptação do artigo
&lt;a href=&quot;https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf&quot; target=&quot;_blank&quot;&gt;A Few Useful Things to Know About Machine Learning&lt;/a&gt; do Pedro Domingos.&lt;/p&gt;

&lt;p&gt;Algoritmos de Aprendizado de Máquina são capazes de aprender como executar diferentes
tarefas a partir de exemplos: uma excelente alternativa nos casos em que desenvolver um
algoritmo é um grande desafio ou tem um grande custo. Os métodos de aprendizao de máquina
têm se tornado bastante populares e aplicações vão desde detecção de spam até o
desenvolvimento de novos remédios.&lt;/p&gt;

&lt;p&gt;Apesar da abundância de material sobre o tema, existem diversas peculiaridades e desafios
na prática. Conhecer essas características reduz o tempo de implementação destes sistemas
além de auxiliar na obtenção de melhores resultados.&lt;/p&gt;

&lt;h3 id=&quot;aprendizado--representao--avaliao--otimizao&quot;&gt;Aprendizado = Representação + Avaliação + Otimização&lt;/h3&gt;

&lt;p&gt;Algoritmos de Aprendizado de Máquina podem ser vistos como uma combinação de três
componentes: representação, avaliação e otimização.&lt;/p&gt;

&lt;h4 id=&quot;representao&quot;&gt;Representação&lt;/h4&gt;

&lt;p&gt;Os classificadores devem ser representados de forma que possam ser interpretados pelo
computador. Quando escolhemos uma representação, estamos também definindo premissas que
limitam o que tal classificador é capaz de aprender. Esse conjunto de possíveis modelos
é conhecido como espaço de hipóteses. Este espaço explica porque alguns classificadores
não são capazes de aprender a calcular o XOR a partir de uma tabela verdade mesmo com
todos os exemplos.&lt;/p&gt;

&lt;p&gt;Por exemplo, o classificador K-nearest neighbors (KNN) utiliza uma representação baseada
em instâncias e a Regressão Logística tem uma representação baseada em hiperplanos.&lt;/p&gt;

&lt;h4 id=&quot;avaliao&quot;&gt;Avaliação&lt;/h4&gt;

&lt;p&gt;A função de avaliação (ou função objetivo) é utilizada para avaliar os classificadores
dentro de um espaço de hipóteses. Desta forma, podemos escolher um bom classificador
dentre todas as possibilidades. Note que a função de avaliação não necessariamente é
a mesma utilizada para avaliar o resultado final do classificador.&lt;/p&gt;

&lt;p&gt;Cada tipo de problema tem uma função de avaliação apropriada. Alguns exemplos são:
acurácia, precisão/revocação e erro ao quadrado.&lt;/p&gt;

&lt;h4 id=&quot;otimizao&quot;&gt;Otimização&lt;/h4&gt;

&lt;p&gt;Por fim, precisamos de um método que utilizará a função de avaliação em uma busca
por boas hipóteses. A escolha do método de otimização é um fator determinante na
eficiência do aprendizado.&lt;/p&gt;

&lt;p&gt;Alguns exemplos de técnicas de otimização são: gradient descent, programação linear,
busca gulosa, branch and bound, etc.&lt;/p&gt;

&lt;h3 id=&quot;a-generalizao-que-conta&quot;&gt;É a generalização que conta&lt;/h3&gt;

&lt;p&gt;O objetivo fundamental do Aprendizado de Máquina é conseguir generalizar o conhecimento
para além das instâncias de treino, uma vez que, na prática, dificilmente o algoritmo
irá se deparar com instâncias previamente vistas. Em uma classificação de documentos
como Spam, com um vocabulário com 100.000 palavras, há \(2^{100000}\) diferentes combinações
de textos de entrada.&lt;/p&gt;

&lt;p&gt;Por isso, é fundamental testar os classificadores em dados que ele ainda não conhece. Ter um score perfeito no conjunto de treino, é tão simples quanto memorizar todos os exemplos fornecidos. Uma das formas mais populares de se avaliar um classificador é utilizando um processo de cross-validation, em que diferentes conjuntos de dados são utilizados para treino e teste.&lt;/p&gt;

&lt;p&gt;Além do cuidado na separação dos conjuntos de dados, é importante garantir que não haverá “vazamento” de informação durante a avaliação. Isso pode ocorrer ao se otimizar parâmetros utilizando o conjunto de teste, ou em features que possam carregar informações sobre a classe que não estarão disponíveis para o classificador em produção.&lt;/p&gt;

&lt;p&gt;É importante seguir uma metodologia de avaliação uma vez que buscamos otimizar uma função que não pode ser acessada (o erro do classificador nas instâncias de teste). Este cuidado ajuda a utilizar o erro conhecido como uma aproximação do erro real (função desconhecida).&lt;/p&gt;

&lt;h3 id=&quot;dados-sozinhos-no-so-o-bastante&quot;&gt;Dados sozinhos não são o bastante&lt;/h3&gt;

&lt;p&gt;Como o principal foco é obter a generalização dos dados apresentados no treino, somente ter exemplos da tarefa não é suficiente. No exemplo do Spam, o número de entradas possíveis pode ser muito grande, de forma que o classificador nunca terá conhecido uma parte expressiva das possibilidades.&lt;/p&gt;

&lt;p&gt;Desta forma, os classificadores devem trazer algum conhecimento próprio, normalmente no formato de suposições sobre os dados. Por exemplo, o classificador Naive Bayes assume que os atributos dos documentos são variáveis independentes.&lt;/p&gt;

&lt;p&gt;Devido a essas suposições, não existe um classificador que seja uma bala de prata do Aprendizado de Máquina. Esta intuição foi formalizada por Wolpert no famoso teorema &lt;em&gt;“no free lunch”&lt;/em&gt;, que diz que um classificador não pode ser melhor que a escolha aleatória em todas as situações.&lt;/p&gt;

&lt;h3 id=&quot;overfitting&quot;&gt;Overfitting&lt;/h3&gt;
&lt;p&gt;Quando tentamos aprender um modelo sem ter uma quantidade suficiente de informação, corremos o risco de generalizar incorretamente peculiaridades dos dados. Este problema é conhecido como &lt;em&gt;overfitting&lt;/em&gt;. Quando um classificador tem 100% de acerto no treino e 50% no teste, enquanto ele deveria ter 75% de acerto em ambos conjuntos, dizemos que este classificador sofre de &lt;em&gt;overfitting&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Uma forma ilustrativa de se compreender tal fenômeno, é separando o erro de generalização em viés (&lt;em&gt;bias&lt;/em&gt;) e variância (&lt;em&gt;variance&lt;/em&gt;). Viés é a tendência de um classificador aprender consistentemente uma generalização incorreta (por exemplo, pela simplicidade do modelo). Variância, é a tendência de se aprender fatos aleatórios independentemente do sinal real. Um classificador capaz de aprender um modelo muito complexo, tem alta variância por ser capaz de aprender padrões que possam não ser reais. Isso faz com que, de forma contra-intuitiva, os classificadores mais complexos não sejam sempre a melhor alternativa.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2015/09/target.png&quot; /&gt;
&lt;/p&gt;

&lt;h3 id=&quot;nossa-intuio--falha-em-alta-dimensionalidade&quot;&gt;Nossa intuição é falha em alta dimensionalidade&lt;/h3&gt;

&lt;p&gt;Outro grande desafio do Aprendizado de Máquina é a &lt;em&gt;maldição da dimensionalidade&lt;/em&gt;. Essa expressão foi criada para se referir ao fato de que algoritmos que funcionam muito bem em baixa dimensionalidade, podem se tornar intratáveis conforme aumenta o número de dimensões. Fixando o número de exemplos, conforme aumentamos a dimensionalidade (número de atributos) passamos a cobrir uma porcentagem cada vez menor das possibilidades de entrada.&lt;/p&gt;

&lt;p&gt;Conforme são adicionadas novas dimensões, ocorre também uma diminuição da distância entre instâncias (a contribuição de uma dimensão no valor final da distância diminui). Isso faz com que representações baseadas em instâncias também sofram com a alta dimensionalidade.&lt;/p&gt;

&lt;p&gt;Desenvolver métodos que atuem em alta dimensionalidade é um grande desafio uma vez que estamos acostumados a pensar em 2D e 3D. Nossa intuição normalmente não funciona em espaços com um grande número de dimensões. Por exemplo, nesse tipo de espaço, a maior parte do volume de uma laranja se encontra em sua casca e não na polpa.&lt;/p&gt;

&lt;p&gt;Um ponto positivo, porém, é que apesar de o espaço ter muitas dimensões, os dados não distibuídos de forma uniforme. Isso significa que os dados normalmente são concentrados de forma a facilitar o aprendizado. Por exemplo, na detecção de dígitos escritos, o número de imagens que fazem sentido é bem menor que o número total de possibilidades.&lt;/p&gt;

&lt;h3 id=&quot;feature-engineering--extremamente-importante&quot;&gt;Feature engineering é extremamente importante&lt;/h3&gt;

&lt;p&gt;Um dos pontos mais importantes para um projeto de Aprendizado de Máquina bem sucedido é a engenharia de atributos. Se os seus dados contém um grande número de features independentes com alta correlação com a classe, então o aprendizado é fácil. Por outro lado, se a classe é o resultado de uma combinação complexa das features, pode ser inviável aprender esta relação.&lt;/p&gt;

&lt;p&gt;Muitas vezes o dado bruto não apresenta as características desejáveis para o aprendizado, porém tais características podem ser obtidas através de algumas transformações. Trabalhar os atributos de forma a facilitar o aprendizado é uma das partes mais importantes do processo e normalmente é aquela que consome a maior parte dos esforços.&lt;/p&gt;

&lt;p&gt;Enquanto algoritmos de aprendizado são relativamente genéricos e agnósticos à aplicação, a engenharia de atributos é completamente dependente do domínio da aplicação. Por isso, existe um grande esforço para se desenvolver sistemas capazes de criar representações de forma automática, como é o caso dos &lt;em&gt;Deep Autoencoders&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;aumentar-o-treinamento-normalmente--mais-eficaz-que-melhorar-o-algoritmo&quot;&gt;Aumentar o treinamento normalmente é mais eficaz que melhorar o algoritmo&lt;/h3&gt;

&lt;p&gt;Muitas vezes nos encontramos em um ponto em que os resultados dos classificadores não são bons o bastante. Nesta situação, existem duas opções: desenvolver um algoritmo melhor ou aumentar a quantidade de exemplos (ou atributos). Pesquisadores normalmente estão interessados na primeira solução, porém a forma mais eficiente de se melhorar a qualidade de modelos é por meio da aquisição de mais informação. Como regra geral, um algoritmo simples com muita informação disponível, é melhor que um algoritmo complexo com poucos dados.&lt;/p&gt;

&lt;h3 id=&quot;concluso&quot;&gt;Conclusão&lt;/h3&gt;

&lt;p&gt;Utilizar algoritmos de Aprendizado de Máquina de forma eficiente exige um conhecimento que nem
sempre pode ser encontrado em livros. Uma forma de adquirir este conhecimento é através da prática
em diferentes domínios. Caso se interesse em ler mais sobre estes e outros pontos o artigo
&lt;a href=&quot;https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;A Few Useful Things to Know About Machine Learning&lt;/em&gt;&lt;/a&gt;
é um excelente ponto de partida.&lt;/p&gt;

</description>
        <pubDate>Mon, 28 Sep 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/machine-learning/2015/09/28/informacoes-uteis-machine-learning/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/machine-learning/2015/09/28/informacoes-uteis-machine-learning/</guid>
        
        
        <category>machine-learning</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 17/08/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;https://indico.io/blog/plotlines/&quot; target=&quot;_blank&quot;&gt;
Exploring the shapes of stories using Python and sentiment APIs
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Kurt Vonnegut apresentou em uma &lt;a href=&quot;https://www.youtube.com/watch?v=oP3c1h8v2ZQ&quot; target=&quot;_blank&quot;&gt;aula&lt;/a&gt; uma formula simples para se analisar histórias
com base no conflito entre bem e mal. Neste post, engenheiros da Indico
utilizam aprendizado de máquina e técnicas de análise de séries
temporais para testar esta hipótese em diferentes filmes da Disney.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://www.alfredo.motta.name/cross-validation-done-wrong/&quot; target=&quot;_blank&quot;&gt;
Cross Validation done wrong
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Cross Validation é uma ferramenta essencial para avaliação de métodos de
aprendizado de máquina. Falhas nesta avaliação podem criar uma falsa
expectativa quanto à verdadeira qualidade dos modelos produzidos. Este
artigo discute um tipo de erro comum em validações cruzadas.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://www.edupristine.com/blog/beyond-k-means&quot; target=&quot;_blank&quot;&gt;
Beyond the k-Means – the Right k
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O K-Means é um algoritmo de clusterização bastante popular. Um dos
desafios práticos é a escolha do número de clusters que devem ser
calculados. Neste post são apresentadas algumas das alternativas para
escolha do valor deste parâmetro.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://www.r2d3.us/visual-intro-to-machine-learning-part-1/&quot; target=&quot;_blank&quot;&gt;
A Visual Introduction to Machine Learning
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;De forma visual e interativa, este experimento traz uma introdução ao
aprendizado de máquina. Eles utilizam a tarefa de determinar se uma casa
está em Nova York ou São Francisco para ilustrar os conceitos de
aprendizado de máquina. É um excelente exemplo de como visualizações
podem facilitar o entendimento de temas complexos.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/rushter/data-science-blogs&quot; target=&quot;_blank&quot;&gt;
Data science blogs
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Este repositório contém uma lista com diversos blogs que tratam sobre
data science.&lt;/p&gt;

</description>
        <pubDate>Mon, 17 Aug 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/08/17/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/08/17/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 20/07/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;http://maximiliankiener.com/digitalprojects/time/&quot; target=&quot;_blank&quot;&gt;
Why time flies
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Conforme o tempo passa, temos, cada vez mais, a sensação de que ele anda
mais rápido. Nessa visualização interativa, Maximilian Kiener mostra
porque um ano dura tanto tempo quando somos crianças e tão pouco quando
adultos.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://kateto.net/network-visualization&quot; target=&quot;_blank&quot;&gt;
Static and dynamic network visualization with R
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;A visualização de redes é muitas vezes essencial para se entender a
relação entre diferentes atores. Em uma rede social, por exemplo, a
visualização pode ajudar a detectar comunidades ou a explicar como a
comunicação flui entre as diferentes pessoas. Neste post, é apresentado
um tutorial completo sobre como utilizar R para criar este tipo de
visualização.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://www.kyunghyuncho.me/home/blog/briefsummaryofthepaneldiscussionatdlworkshopicml2015&quot; target=&quot;_blank&quot;&gt;
Brief Summary of the Panel Discussion at Deep Learning Workshop
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Este mês ocorreu mais uma edição da International Conference on Machine
Learning (ICML), que é uma das mais importantes conferências sobre
aprendizado de máquina. Em um painel sobre Deep Learning seis
importantes pesquisadores discutiram temas como indústria versus
universidades, os perigos da inteligência artificial e novas tendências.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://nerds.airbnb.com/scaling-data-science/&quot; target=&quot;_blank&quot;&gt;
At Airbnb, Data Science Belongs Everywhere: Insights from Five Years of
Hypergrowth
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Ouvir e entender os clientes são partes fundamentais de qualquer
negócio. Prover este tipo de informação de forma rápida e acessível a
todos não é uma tarefa fácil e exige alguma metodologia escalável. Neste
post, um data scientist do Airbnb conta como eles promoveram o acesso
aos dados em uma empresa em rápido crescimento.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://techblog.netflix.com/2015/07/tracking-down-villains-outlier.html&quot; target=&quot;_blank&quot;&gt;
Tracking down the Villains: Outlier Detection at Netflix
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Detecção de outliers é útil em diferentes cenários. Uma possível
aplicação é na identificação de servidores que não estão performando
corretamente. Neste post, o Netflix apresenta como soluciona este
problema utilizando um algoritmo de clusterização.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://iamtrask.github.io/2015/07/12/basic-python-network/&quot; target=&quot;_blank&quot;&gt;
A Neural Network in 11 lines of Python
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Redes neurais podem ter diferentes arquiteturas e níveis de
complexidade. Para quem deseja conhecer esta área, este post pode ser um
bom primeiro passo. O autor apresenta de forma gradativa o funcionamento
de uma rede neural simples, assim como o algoritmo para seu treinamento
(backpropagation).&lt;/p&gt;

</description>
        <pubDate>Mon, 20 Jul 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/07/20/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/07/20/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 07/07/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;http://www.bayesimpact.org/&quot; target=&quot;_blank&quot;&gt;
Bayes Impact
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;A Bayes Impact é uma Organização não Governamental mundial comprometida
em solucionar grandes problemas utilizando Data Science. Em seu &lt;a href=&quot;http://www.bayesimpact.org/stories&quot; target=&quot;_blank&quot;&gt;blog&lt;/a&gt; é
possível entender como a ONG enfrenta os desafios e qual o seu processo
de análise dos dados.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://www.analyticsvidhya.com/blog/2015/06/solution-kaggle-competition-bike-sharing-demand/&quot; target=&quot;_blank&quot;&gt;
Kaggle Bike Sharing Demand Prediction
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Neste post, Sunil Ray mostra o processo que utilizou na competição do
Kaggle para predição de demanda de aluguel de bicicletas. Descreve-se
desde a análise dos dados até a criação dos atributos (feature
engineering) e aplicação dos algoritmos de aprendizado de máquina.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://nerds.airbnb.com/designing-machine-learning-models/&quot; target=&quot;_blank&quot;&gt;
Designing Machine Learning Models: A Tale of Precision and Recall
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O AirBNB utiliza aprendizado de máquina para solucionar diversos
problemas internos, como detecção de transações fraudulentas. Neste
post, uma engenheira compartilha quais são os primeiros passos para a
criação e avaliação de modelos de aprendizado de máquina. Este conteúdo
é uma boa leitura para quem desejar iniciar na área.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/wbkd/awesome-d3&quot; target=&quot;_blank&quot;&gt;
Awesome D3
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O &lt;a href=&quot;http://d3js.org/&quot; target=&quot;_blank&quot;&gt;D3&lt;/a&gt; é uma biblioteca
para a manipulação de documentos baseada em dados. Cada vez mais, esta
biblioteca vem se tornando o padrão para visualizações no browser
(interativas ou não). O repositório awesome-d3 é uma lista que organiza
algumas das opções para se aprender ou utilizar o D3.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/ChristosChristofidis/awesome-deep-learning&quot; target=&quot;_blank&quot;&gt;
Awesome Deep Learning
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Neste repositório é possível ver uma lista de links curados sobre Deep
Learning. Nesta lista podem ser encontrados materiais como cursos,
tutoriais, artigo, frameworks e outros.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://www.kaggle.com/c/otto-group-product-classification-challenge/forums/t/14335/1st-place-winner-solution-gilberto-titericz-stanislav-semenov/79598#post79598&quot; target=&quot;_blank&quot;&gt;
Solução vencedora do Otto Group Classification Challenge
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O Otto Group Classification Challenge contou com a participação de quase
4 mil data scientists, tornando-se um dos desafios mais populares do
Kaggle. Neste post, o time vencedor explica sua estratégia baseada em
ensemble que utilizada 33 modelos diferentes no primeiro nível. A
estratégia utilizada pelo segundo colocado pode ser vista
&lt;a href=&quot;http://blog.kaggle.com/2015/06/09/otto-product-classification-winners-interview-2nd-place-alexander-guschin/&quot; target=&quot;_blank&quot;&gt;aqui&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Tue, 07 Jul 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/07/07/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/07/07/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 23/06/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;https://code.facebook.com/posts/861999383875667/recommending-items-to-more-than-a-billion-people/&quot; target=&quot;_blank&quot;&gt;
Recommending items to more than a billion people
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Este artigo mostra como o Facebook utilizou o 
&lt;a href=&quot;http://giraph.apache.org/&quot; target=&quot;_blank&quot;&gt;Apache Giraph&lt;/a&gt; 
para escalar
seu sistema de recomendação para 100 bilhões de avaliações, mais de um
bilhão de usuários e milhões de itens. Esta implementação de
Collaborative Filtering modela o processamento como um grafo, que reduz
o volume de dados transportados por rede e que funciona de forma
eficiente mesmo para datasets enviesados  (com alguns items avaliados
por um número muito grande de usuários).&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://www.technologyreview.com/view/537891/virtual-eyes-train-deep-learning-algorithm-to-recognize-gaze-direction/&quot; target=&quot;_blank&quot;&gt;
Virtual Eyes Train Deep Learning Algorithm to Recognize Gaze Direction
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Modelos complexos de Aprendizado de Máquina podem demandar grandes
quantidades de informações para alcançar  bons resultados. Obter tais
dados pode ser custoso, por exemplo no caso de detecção da direção do
olhar. Pesquisadores da Inglaterra e Alemanha encontraram uma 
&lt;a href=&quot;http://arxiv.org/abs/1505.05916&quot; target=&quot;_blank&quot;&gt;forma
criativa&lt;/a&gt; para solucionar este problema: as imagens de treinamento são
geradas a partir de modelos 3D de olhos.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://nerds.airbnb.com/aerosolve&quot; target=&quot;_blank&quot;&gt;
Aerosolve: Machine learning for humans
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O Airbnb utiliza Aprendizado de Máquina para, entre outras aplicações,
estimar a probabilidade de um imóvel ser alugado, dado o preço da sua
diária e outros atributos. A biblioteca utilizada para esta análise foi
publicada recentemente com uma licença 
&lt;a href=&quot;https://github.com/airbnb/aerosolve&quot; target=&quot;_blank&quot;&gt;open-source&lt;/a&gt;. 
Seu diferencial  é
possibilitar o trabalho conjunto entre humanos e máquinas, obtendo
melhores resultados que cada um isoladamente.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;https://github.com/donnemartin/data-science-ipython-notebooks&quot; target=&quot;_blank&quot;&gt;
Data Science IPython Notebooks
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O &lt;a href=&quot;http://ipython.org/&quot; target=&quot;_blank&quot;&gt;IPython Notebook&lt;/a&gt;
é uma excelente ferramenta para se realizar
análises exploratórias de bases de dados e documentar os resultados
obtidos. Este repositório contém um enorme número de Notebooks com
exemplos de uso de ferramentas e bibliotecas como matplotlib, spark,
scikit-learn, pandas e outros.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://googleresearch.blogspot.com.br/2015/06/inceptionism-going-deeper-into-neural.html&quot; target=&quot;_blank&quot;&gt;
Inceptionism: Going Deeper into Neural Networks
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Uma forma de se entender melhor o comportamento de uma rede neural é
invertendo o seu comportamento. Por exemplo, ao invés de utiliza-la para
classificar uma imagem, a rede é utilizada para realçar em uma imagem
(que pode ser inicialmente ruído) os atributos aprendidos. Pesquisadores
do Google utilizaram este processo em uma rede neural treinada para
reconhecer diversos objetos. Os resultados são imagens muito
interessantes, que podem ser vistas nesta 
&lt;a href=&quot;https://photos.google.com/share/AF1QipPX0SCl7OzWilt9LnuQliattX4OUCj_8EP65_cTVnBmS1jnYgsGQAieQUc1VQWdgQ?key=aVBxWjhwSzg2RjJWLWRuVFBBZEN1d205bUdEMnhB&quot; target=&quot;_blank&quot;&gt;galeria&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;a href=&quot;http://www.startup.ml/blog/hyperparam&quot; target=&quot;_blank&quot;&gt;
State of Hyperparameter Selection
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Muitas vezes, avaliar conjuntos de parâmetros demanda um grande
investimento de tempo. Por isso, testar diversas possibilidades e
escolher o melhor resultado é um desafio prático do Aprendizado de
Máquina. Neste post, são apresentadas formas mais eficientes para a
escolha dos parâmetros, evitando, assim, o teste de todas as
possibilidades.&lt;/p&gt;
</description>
        <pubDate>Tue, 23 Jun 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/06/23/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/06/23/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 01/06/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot; target=&quot;_blank&quot;&gt;
The Unreasonable Effectiveness of Recurrent Neural Networks
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Recurrent Neural Networks (RNN) são utilizadas quando o processamento
dos dados é feito de forma sequencial. Por exemplo, no reconhecimento de
texto escrito a mão e na 
&lt;a href=&quot;http://cs.stanford.edu/people/karpathy/deepimagesent/&quot; target=&quot;_blank&quot;&gt;
descrição automática de imagens&lt;/a&gt;. Este post
apresenta uma explicação breve sobre RNNs além de um exemplo de geração
de texto caractere por caractere.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://datascience.la/benchmarking-random-forest-implementations/&quot; target=&quot;_blank&quot;&gt;
Benchmarking Random Forest Implementations
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Benchmark com diversas implementações de Random Forest levando em conta
a qualidade do modelo e o tempo de processamento. O objetivo é encontrar
uma implementação que possa ser utilizada no processamento de datasets
com dez milhões de instâncias.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://yahoolabs.tumblr.com/post/118966433256/egads-a-scalable-configurable-and-novel-anomaly&quot; target=&quot;_blank&quot;&gt;
EGADS: A Scalable, Configurable, and Novel Anomaly Detection System
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;A detecção de anomalias em séries temporais é uma importante ferramenta
para um Data Scientist. No caso do Yahoo Mail e Flickr, esse tipo de
análise é conduzida nas métricas vitais do produto sempre que uma nova
feature chega em produção. O código utilizado para detectar tais desvios
pode ser acessado neste 
&lt;a href=&quot;https://github.com/yahoo/egads&quot; target=&quot;_blank&quot;&gt;link&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://warkmilson.com/2015/05/15/three-years-of-logging-my-inbox-count.html&quot; target=&quot;_blank&quot;&gt;
Three Years of Logging My Inbox Count
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Seguidores da filosofia Inbox Zero irão se identificar com Mark Wilson.
Após três anos coletando seus emails, Mark realiza uma análise de
diversos aspectos relacionados ao tempo de resposta e explora uma grande
fonte de stress: o número de posts em sua caixa de entrada.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://blog.dato.com/how-to-evaluate-machine-learning-models-part-1-orientation&quot; target=&quot;_blank&quot;&gt;
How to Evaluate Machine Learning Models
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Série de posts que introduz como deve ser conduzida a avaliação de
modelos de aprendizado de máquina. Conceitos abordados incluem: matriz
de confusão, métricas de classificação e ranking, cross-validation e
hyperparameter tuning.&lt;/p&gt;

&lt;h3&gt;&lt;a href=&quot;http://spin.atomicobject.com/2015/05/26/mean-shift-clustering/&quot; target=&quot;_blank&quot;&gt;
Mean Shift Clustering
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Explicação sobre o algoritmo de clusterização Mean Shift com animações,
gráficos, código e exemplo de aplicação na segmentação de imagens.&lt;/p&gt;
</description>
        <pubDate>Mon, 01 Jun 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/06/01/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/06/01/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 18/05/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;http://instagram-engineering.tumblr.com/post/117889701472/emojineering-part-1-machine-learning-for-emoji&quot; target=&quot;_blank&quot;&gt;
Emojineering
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Neste estudo, o Instagram analisa a adoção e o uso de emojis em seus
posts. Utilizando o &lt;a href=&quot;https://code.google.com/p/word2vec/&quot; target=&quot;_blank&quot;&gt;word2vec&lt;/a&gt;, 
a equipe analisou qual o contexto de cada emoji e quais palavras eles 
normalmente representam.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://engineering.flipboard.com/2015/05/scaling-convnets/&quot; target=&quot;_blank&quot;&gt;
Image Scaling using Deep Convolutional Neural Networks
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Redes neurais tem se tornado cada vez mais utilizadas por apresentarem
bons resultados nas mais diversas áreas. Nesse post, a equipe do
Flipboard apresenta alguns experimentos de redimensionamento de imagens
utilizando Convolutional Neural Networks. O post ainda apresenta uma boa
revisão dos conceitos de redes neurais.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://nerds.airbnb.com/overcoming-missing-values-in-a-rfc/&quot; target=&quot;_blank&quot;&gt;
Overcoming Missing Values in a Random Forest Classifier
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Um dos desafios do trabalho com dados é lidar com bases que tenham
informações incompletas. Existem diversas formas de lidar com este
problema que vão desde o descarte da entrada incompleta até a estimativa
dos valores desconhecidos. Neste post a equipe do AirBNB mostra como
utiliza árvores de decisão para lidar com bases de dados com esta
característica.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://www.odbms.org/blog/2015/04/powering-big-data-at-pinterest-interview-with-krishna-gade/&quot; target=&quot;_blank&quot;&gt;
Powering Big Data at Pinterest
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Entrevista com Krishna Grade, engenheiro do time de dados do Pinterest,
em que ele conta como é trabalhar com um produto e uma empresa com foco
em dados. Além dos desafios do dia-a-dia, também são abordadas as
tecnologias utilizadas na infraestrutura do Pinterest.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://blog.dato.com/parallel-ml-with-hogwild&quot; target=&quot;_blank&quot;&gt;
Parallel Machine Learning with Hogwild!
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Algoritmos paralelos podem gastar um tempo significativo obtendo e
liberando locks. Em alguns casos, uma técnica chamada Hogwild! pode ser
utilizada para substituir o lock sem grandes prejuízos no resultado
final.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;https://research.facebook.com/researchers/1543934539189348&quot; target=&quot;_blank&quot;&gt;
The bAbI project
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O Facebook divulgou um dataset artificial com tarefas que podem ser
utilizadas para testar o entendimento de textos e a conexão entre fatos.
As tarefas foram construidas isolando diferentes aspectos da
interpretação de texto, permitindo a construção de testes de capacidades
específicas dos modelos de aprendizado. Abaixo, um exemplo de tarefa
“pergunta e resposta suportada por um fato”:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fato 1:&lt;/strong&gt; Mary foi ao banheiro&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fato 2:&lt;/strong&gt; John foi ao escritório&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Onde está Mary?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resposta:&lt;/strong&gt; No banheiro (baseado no &lt;em&gt;Fato 2&lt;/em&gt;)&lt;/p&gt;

</description>
        <pubDate>Mon, 18 May 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/05/18/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/05/18/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 04/05/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;https://github.com/fchollet/keras&quot; target=&quot;_blank&quot;&gt;
Keras: biblioteca de Deep Learning
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Keras é uma biblioteca minimalista e modular para prototipação de redes
neurais. Ela utiliza a Theano para realizar computações eficientes em
CPU e GPU e suporta &lt;em&gt;convolutional&lt;/em&gt; e &lt;em&gt;recurrent networks&lt;/em&gt;.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://www.john-foreman.com/blog/surviving-data-science-at-the-speed-of-hype&quot; taget=&quot;_blank&quot;&gt;
Surviving Data Science &quot;at the Speed of Hype&quot;
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Neste artigo, John Foreman descreve como é ser um Data Scientist em mercados e ambientes de incerteza e rápidas mudanças. Ele argumenta que modelos complexos de aprendizado de máquina demandam um ambiente estável - no mínimo, para concepção dos modelos e construção de um bom treino, por exemplo. Nesses casos, análises mais simples têm maior valor.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://www.dear-data.com/&quot; taget=&quot;_blank&quot;&gt;
Dear Data
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Projeto em que visualizações de dados são feitas manualmente e trocadas
entre duas artistas. Com o objetivo de se conhecerem melhor, toda semana
elas definem um tópico, coletam os dados e trocam cartões postais com as visualizações criadas.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://www-labs.iro.umontreal.ca/~bengioy/dlbook/&quot; taget=&quot;_blank&quot;&gt;
Livro sobre Deep Learning
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Yoshua Bengio &lt;em&gt;et al&lt;/em&gt; publicaram uma nova versão do livro sobre Deep
Learning. Três novos capítulos foram adicionados, além de diversas
melhorias e uma reorganização do livro em três partes.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/&quot; taget=&quot;_blank&quot;&gt;
Deep Learning e processamento de linguagem natural
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Este post aborda aplicações de Deep Learning no processamento
de linguagem natural. Mais específicamente, o autor fala sobre a
representação dos atributos e a sua utilização em redes neurais.&lt;/p&gt;

</description>
        <pubDate>Mon, 04 May 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/05/04/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/05/04/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
      <item>
        <title>Links Selecionados - 17/03/2015</title>
        <description>&lt;h3&gt;&lt;a href=&quot;http://www.washingtonpost.com/blogs/wonkblog/wp/2015/03/03/a-scientific-explanation-of-what-makes-indian-food-so-delicious/&quot; target=&quot;_blank&quot;&gt;
Desvendando a culinária Indiana&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Um grupo de cientistas identificou o que torna a comida indiana única. A
partir de uma análise de milhares de receitas, os pesquisadores
descobriram que existe uma tendência de se utilizar ingredientes que não
tenham interseção de sabores.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://behindthesite.com/&quot; taget=&quot;_blank&quot;&gt;
Behind The Site
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O BehindTheSite é um repositório de informações sobre os softwares e
serviços utilizados em diferentes empresas e produtos.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;https://blog.compose.io/is-postgresql-your-next-json-database/&quot; taget=&quot;_blank&quot;&gt;
PostgreSQL + JSON
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;O PostgreSQL está cada vez mais capaz de armazenar e tratar documentos
em formato JSON. Este artigo é um estudo sobre a possibilidade de se
utilizar o Postgre como um substituto para o MongoDB. A resposta curta
é: o Postgre poderia ser utilizado se não houver necessidade de
atualizar os documentos frequentemente.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;https://www.mapr.com/real-world-hadoop&quot; taget=&quot;_blank&quot;&gt;
Real-World Hadoop
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Um livro gratuito com informações sobre o ecossistema hadoop e estudos
de caso.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://spark.apache.org/releases/spark-release-1-3-0.html&quot; taget=&quot;_blank&quot;&gt;
Apache Spark 1.3
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Uma nova versão do Spark foi lançada. Uma das novidades desta versão é a
API de &lt;a href=&quot;https://databricks.com/blog/2015/03/13/announcing-spark-1-3.html&quot; target=&quot;_blank&quot;&gt;DataFrame&lt;/a&gt; inspirada nos DataFrames de R. Este será um formato
comum para comunicação e interoperabilidade.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;https://timdettmers.wordpress.com/2015/03/09/deep-learning-hardware-guide/&quot; taget=&quot;_blank&quot;&gt;
Guia de Hardware para Deep Learning
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Para se utilizar Deep Learning de forma competitiva é necessário um
grande poder computacional. Para auxiliar na escolha do hardware, Tim
Dettmers preparou um guia que cobre desde a escolha da placa gráfica até
os coolers e monitores.&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://jasmcole.com/2015/03/02/two-come-along-at-once/&quot; taget=&quot;_blank&quot;&gt;
Dois ônibus de uma vez
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Análise das rotas dos ônibus de Londres para responder a pergunta:
sempre que há atraso dois ônibus chegam juntos?&lt;/p&gt;

&lt;h3 class=&quot;title-space&quot;&gt;&lt;a href=&quot;http://www.kdnuggets.com/2015/02/history-data-science-infographic.html&quot; taget=&quot;_blank&quot;&gt;
Data Science em infográfico
&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Infográfico que apresenta o surgimento da Data Science a partir da união
de cinco campos: Ciência da Computação, Tecnologia dos Dados,
Visualização, Matemática e Estatística.&lt;/p&gt;
</description>
        <pubDate>Tue, 17 Mar 2015 00:00:00 -0300</pubDate>
        <link>http://www.behavedata.com/blog/links/2015/03/17/links-selecionados/</link>
        <guid isPermaLink="true">http://www.behavedata.com/blog/links/2015/03/17/links-selecionados/</guid>
        
        
        <category>links</category>
        
      </item>
    
  </channel>
</rss>
